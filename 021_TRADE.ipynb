{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45c5214-e8dd-42a3-9f0d-8c83fd626370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time as dt_time, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "import pandas_ta as ta\n",
    "from rdp import rdp\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import savgol_filter\n",
    "from datetime import datetime, date, time as dt_time, timedelta\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "API_KEY = \"vBRy5un9PuHfxFj1IrHpfg8a2RS57jE9\"\n",
    "\n",
    "# https://github.com/polygon-io/client-python/blob/master/examples/websocket/stocks-ws.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d8e9bc-9ee7-476e-98b7-55fbad3279c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_polygon_data(ticker: str, api_key: str,\n",
    "                              start_date: date,\n",
    "                              end_date: date,\n",
    "                              start_time: dt_time,\n",
    "                              end_time: dt_time = dt_time(16, 0),\n",
    "                              multiplier: int = 1,\n",
    "                              timespan: str = \"minute\",\n",
    "                              limit: int = 50000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches intraday minute-level OHLCV data for a given ticker from Polygon.io.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol (e.g., \"TSLA\").\n",
    "        api_key (str): Your Polygon.io API key.\n",
    "        start_date (date): The date for which to fetch data.\n",
    "        end_date (date): The date for which to end fetch data.\n",
    "        start_time (datetime.time): Start of time window in EST.\n",
    "        end_time (datetime.time): End of time window in EST.\n",
    "        multiplier (int): Interval multiplier (default 1 minute).\n",
    "        timespan (str): Time unit (\"minute\", \"hour\", etc.).\n",
    "        limit (int): Maximum number of results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame with renamed columns and timestamps in EST.\n",
    "    \"\"\"\n",
    "    ET_ZONE = ZoneInfo(\"America/New_York\")\n",
    "\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{start_date}/{end_date}\"\n",
    "    params = {\n",
    "        \"apiKey\": api_key,\n",
    "        \"adjusted\": \"true\",\n",
    "        \"sort\": \"asc\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    bars = response.json().get(\"results\", [])\n",
    "    df = pd.DataFrame(bars)\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data\n",
    "\n",
    "    df[\"TIME_UTC\"] = pd.to_datetime(df[\"t\"], unit=\"ms\", utc=True)\n",
    "    df[\"TIME_EST\"] = df[\"TIME_UTC\"].dt.tz_convert(ET_ZONE)\n",
    "    del df[\"TIME_UTC\"]\n",
    "\n",
    "    # Define time window\n",
    "    start_dt = datetime.combine(start_date, start_time, tzinfo=ET_ZONE)\n",
    "    end_dt = datetime.combine(end_date, end_time, tzinfo=ET_ZONE)\n",
    "\n",
    "    # Filter and rename\n",
    "    df = df[(df[\"TIME_EST\"] >= start_dt) & (df[\"TIME_EST\"] <= end_dt)].copy()\n",
    "    df.rename(columns={\n",
    "        \"o\": \"open\",\n",
    "        \"h\": \"high\",\n",
    "        \"l\": \"low\",\n",
    "        \"c\": \"close\",\n",
    "        \"v\": \"volume\",\n",
    "        \"n\": \"trades\",\n",
    "        \"vw\": \"vwap\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c14898-da4c-4db7-a051-9a40dcb2f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_indicators_and_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds technical indicators, buy conditions, and entry signal column to the given DataFrame.\n",
    "    Assumes columns: 'open', 'high', 'low', 'close', 'volume'\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with new columns added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Bollinger Bands_________________________________________________________\n",
    "    # ________________________________________________________________________\n",
    "\n",
    "    up, _, dn = talib.BBANDS(df.close.values, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "    df['BB_up_2'], df['BB_dn_2'] = up, dn\n",
    "\n",
    "    up, _, dn = talib.BBANDS(df.close.values, timeperiod=20, nbdevup=1, nbdevdn=1)\n",
    "    df['BB_up_1'], df['BB_dn_1'] = up, dn\n",
    "\n",
    "    # VWAP (Cumulative approximation)_________________________________________\n",
    "    # ________________________________________________________________________\n",
    "\n",
    "    start_time = dt_time(4, 0)   # ex.,4:00 AM ET\n",
    "    end_time = dt_time(23, 59)  \n",
    "\n",
    "    mask = (df['TIME_EST'].dt.time >= start_time) & (df['TIME_EST'].dt.time <= end_time)\n",
    "    df_trading = df.loc[mask].copy()\n",
    "\n",
    "    df.loc[mask, 'VWAP_Cum'] = ((df.loc[mask, 'close'] * df.loc[mask, 'volume']).groupby(df.loc[mask, 'TIME_EST'].dt.date).cumsum()\n",
    "                                /\n",
    "                                df.loc[mask, 'volume'].groupby(df.loc[mask, 'TIME_EST'].dt.date).cumsum())\n",
    "\n",
    "    # EMA, MACD, ATR, SMA ____________________________________________________\n",
    "    # ________________________________________________________________________\n",
    "\n",
    "    macd, sig, hist = talib.MACD(df.close.values, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['MACD'], df['Signal'], df['MACD_hist'] = macd, sig, hist\n",
    "\n",
    "    # EMA, MACD, ATR, SMA     ----------------------------\n",
    "    df['EMA9'] = talib.EMA(df.close.values, timeperiod=9)\n",
    "    df['EMA20'] = talib.EMA(df.close.values, timeperiod=20)\n",
    "    df['EMA50'] = talib.EMA(df.close.values, timeperiod=50)\n",
    "    df['EMA200'] = talib.EMA(df.close.values, timeperiod=200)\n",
    "\n",
    "    macd, sig, hist = talib.MACD(df.close.values, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['MACD'], df['Signal'], df['MACD_hist'] = macd, sig, hist\n",
    "    df[\"MACD_hist_smooth_EMA\"] = df[\"MACD_hist\"].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "    df['SMA5'] = talib.SMA(df.close.values, timeperiod=5)\n",
    "    df['SMA20'] = talib.SMA(df.close.values, timeperiod=20)\n",
    "    df['SMA50'] = talib.SMA(df.close.values, timeperiod=50)\n",
    "    df['SMA200'] = talib.SMA(df.close.values, timeperiod=200)\n",
    "\n",
    "    # RSI                     ----------------------------  \n",
    "    df['RSI'] = talib.RSI(df.close.values, timeperiod=14)\n",
    "    \n",
    "    # TSI                     ________________________________________________\n",
    "    # ________________________________________________________________________\n",
    "\n",
    "    tsi_df = ta.tsi(df['close'], long=25*4, short=13*4, signal=8*4)\n",
    "    tsi_df.index = df.index  # Align index to match df\n",
    "    tsi_df.columns = ['TSI', 'TSI_signal']\n",
    "    df = df.join(tsi_df)\n",
    "    \n",
    "    # Confriming Signal_______________________________________________________\n",
    "    # ________________________________________________________________________\n",
    "    \n",
    "    df['SMA200_VL']=df['SMA200'].diff()\n",
    "    df['SMA50_VL']=df['SMA50'].diff()\n",
    "\n",
    "    # zscored_signal = zscore(df[['SMA50_VL','SMA200_VL']].values, axis=0, ddof=0, nan_policy='omit')\n",
    "    # df[['SMA50_VL_ZSCR', 'SMA200_VL_ZSCR']] = zscored_signal\n",
    "    \n",
    "    # --- Daily z-score of the diff columns (resets each day) ---\n",
    "    _seg = df.loc[mask] \n",
    "    \n",
    "    out = (\n",
    "        _seg\n",
    "        .groupby(_seg['TIME_EST'].dt.date, group_keys=False)[['SMA50_VL','SMA200_VL']]\n",
    "        .apply(lambda g: pd.DataFrame(\n",
    "            zscore(g.to_numpy(), axis=0, ddof=0, nan_policy='omit'),\n",
    "            index=g.index,\n",
    "            columns=['SMA50_VL_ZSCR_DAY','SMA200_VL_ZSCR_DAY']\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    # Assign back aligned by index\n",
    "    df[['SMA50_VL_ZSCR_DAY','SMA200_VL_ZSCR_DAY']] = np.nan\n",
    "    df.loc[out.index, ['SMA50_VL_ZSCR_DAY','SMA200_VL_ZSCR_DAY']] = out\n",
    "    \n",
    "    # smoothed Signal         ----------------------------\n",
    "    df['SMA50_VL_smooth'] = savgol_filter(df['SMA50_VL'], window_length=150, polyorder=7)\n",
    "    df['SMA200_VL_smooth'] = savgol_filter(df['SMA200_VL'], window_length=150, polyorder=7)\n",
    "\n",
    "    zscored_signal= zscore(df[['SMA50_VL_smooth','SMA200_VL_smooth']].values, axis=0, ddof=0, nan_policy='omit')\n",
    "    df[['SMA50_VL_ZSCR_smooth', 'SMA200_VL_ZSCR_smooth']] = zscored_signal \n",
    "\n",
    "    # --- Daily z-score of the smoothed columns (resets each day) ---\n",
    "    _seg = df.loc[mask] \n",
    "    \n",
    "    out = (\n",
    "        _seg\n",
    "        .groupby(_seg['TIME_EST'].dt.date, group_keys=False)[['SMA50_VL_smooth','SMA200_VL_smooth']]\n",
    "        .apply(lambda g: pd.DataFrame(\n",
    "            zscore(g.to_numpy(), axis=0, ddof=0, nan_policy='omit'),\n",
    "            index=g.index,\n",
    "            columns=['SMA50_VL_ZSCR_smooth_DAY','SMA200_VL_ZSCR_smooth_DAY']\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    # Assign back aligned by index\n",
    "    df[['SMA50_VL_ZSCR_smooth_DAY','SMA200_VL_ZSCR_smooth_DAY']] = np.nan\n",
    "    df.loc[out.index, ['SMA50_VL_ZSCR_smooth_DAY','SMA200_VL_ZSCR_smooth_DAY']] = out\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2064aa21-682a-4fa3-acc4-df7a99bc3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "def fetch_multiple_tickers_data(ticker: List[str],\n",
    "                                api_key: str,\n",
    "                                start_date: date,\n",
    "                                end_date: date,\n",
    "                                start_time: dt_time,\n",
    "                                end_time: dt_time,\n",
    "                                multiplier: int,\n",
    "                                timespan: str,\n",
    "                                limit: int ,\n",
    "                                delay: float = 0.25) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch minute-level Polygon data for multiple tickers on a given date.\n",
    "\n",
    "    Args:\n",
    "        ticker (List[str]): List of stock ticker symbols.\n",
    "        api_key (str): Your Polygon.io API key.\n",
    "        start_date (date): The date for which to fetch intraday data.\n",
    "        delay (float): Seconds to wait between API calls (rate limit buffer).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Dictionary of ticker symbol â†’ DataFrame.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "\n",
    "    for ticker in ticker:\n",
    "        try:\n",
    "            df = fetch_polygon_data(\n",
    "                ticker=ticker,\n",
    "                api_key=API_KEY,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                multiplier=multiplier,\n",
    "                timespan=timespan,\n",
    "                limit=limit\n",
    "                )\n",
    "            if not df.empty:\n",
    "                \n",
    "                df = add_indicators_and_signals(df)\n",
    "\n",
    "                all_data[ticker] = df\n",
    "\n",
    "            print(f\"âœ… {ticker} - fetched {len(df)} rows\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error fetching {ticker}: {e}\")\n",
    "\n",
    "        time.sleep(delay) # â±ï¸ Avoid hitting rate limits\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75264ed4-9b71-4cac-95cb-4cabb949f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_intraday(df, ticker):\n",
    "    fig = make_subplots(\n",
    "        rows=6, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        specs=[\n",
    "            [{\"secondary_y\": True}],  # Row 1\n",
    "            [{}], [{}], [{}], [{}], [{}]  # Rows 2-6\n",
    "        ],\n",
    "        row_heights=[0.3, 0.15, 0.15, 0.08, 0.15, 0.15],\n",
    "        vertical_spacing=0.02,\n",
    "        subplot_titles=(\"Price + BB + VWAP\", \"RSI5\", \"MACD Hist, MACD & Signal\", \"TSI\", \"V\", \"A\")\n",
    "    )\n",
    "\n",
    "    # Row 1: Price + BB + VWAP\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=df[\"TIME_EST\"], open=df[\"open\"], high=df[\"high\"],\n",
    "        low=df[\"low\"], close=df[\"close\"], name=\"Price\"\n",
    "    ), row=1, col=1, secondary_y=False)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"BB_up_1\"], line=dict(dash=\"dash\"), name=\"BB Up 1\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"BB_dn_1\"], fill=\"tonexty\",fillcolor=\"rgba(200,200,200,0.2)\", name=\"BB Dn 1\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"VWAP_Cum\"], line=dict(dash=\"dot\"), name=\"VWAP\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"EMA200\"], line=dict(color=\"orange\"), name=\"EMA200\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"SMA200\"], line=dict(color=\"blue\"), name=\"SMA200\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"SMA50\"], line=dict(color=\"black\"), name=\"SMA50\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"EMA50\"], line=dict(color=\"khaki\"), name=\"EMA50\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"SMA5\"], line=dict(color=\"gray\"), name=\"SMA5\"), row=1, col=1)\n",
    "\n",
    "    # Row 1: Volume zones\n",
    "    df['volume_color'] = np.where(df['close'] > df['close'].shift(1), 'green',\n",
    "                                  np.where(df['close'] < df['close'].shift(1), 'red', 'gray'))\n",
    "    fig.add_trace(go.Bar(x=df[\"TIME_EST\"], y=df[\"volume\"], name=\"Vol\",\n",
    "                         marker_color=df[\"volume_color\"], width=1000, opacity=.3, marker_line_width=0),\n",
    "                  row=1, col=1, secondary_y=True)\n",
    "\n",
    "    # Row 2: RSI5\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"RSI\"], name=\"RSI\", line=dict(color=\"olive\")), row=2, col=1)\n",
    "    for level in [70, 50, 30]:\n",
    "        fig.add_hline(y=level, line_dash=\"dash\", row=2, col=1)\n",
    "\n",
    "    # Row 3: MACD Histogram, MACD & Signal\n",
    "    hist_colors = ['green' if val >= 0 else 'red' for val in df[\"MACD_hist\"]]\n",
    "    fig.add_trace(go.Bar(x=df[\"TIME_EST\"], y=df[\"MACD_hist\"],\n",
    "                         marker=dict(color=hist_colors, line=dict(color=hist_colors, width=1)),\n",
    "                         name='MACD Hist'), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['MACD'], line=dict(color='olive', width=2), name='MACD'), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"Signal\"], line=dict(color=\"salmon\", width=1), name=\"Signal\"), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df[\"MACD_hist_smooth_EMA\"],\n",
    "                             line=dict(color=\"brown\", width=1), name=\"MACD_hist_smooth_EMA\"), row=3, col=1)\n",
    "\n",
    "    # Row 4: TSI\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['TSI'], line=dict(color='red', width=2), name='TSI'), row=4, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['TSI_signal'], line=dict(color='blue', width=2), name='TSI_signal'), row=4, col=1)\n",
    "    for level in [-25, 0, 25]:\n",
    "        fig.add_hline(y=level, line_dash=\"dash\", row=4, col=1)\n",
    "\n",
    "    # Row 5: V-A\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA50_VL_ZSCR_DAY'], line=dict(color='black', width=1), name='SMA50_VL_ZSCR_DAY'), row=5, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA200_VL_ZSCR_DAY'], line=dict(color='blue', width=1), name='SMA200_VL_ZSCR_DAY'), row=5, col=1)\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", row=5, col=1)\n",
    "\n",
    "\n",
    "    # Row 6: V-A AC\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA50_VL_ZSCR_smooth'], line=dict(color='rgba(0, 0, 0, 0.15)', width=1), name='SMA50_VL_ZSCR_smooth'), row=6, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA200_VL_ZSCR_smooth'], line=dict(color='rgba(70, 130, 180, 0.35)', width=1), name='SMA200_VL_ZSCR_smooth'), row=6, col=1)\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", row=6, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA50_VL_ZSCR_smooth_DAY'], line=dict(color='black', width=1), name='SMA50_VL_ZSCR_smooth_DAY'), row=6, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df[\"TIME_EST\"], y=df['SMA200_VL_ZSCR_smooth_DAY'], line=dict(color='blue', width=1), name='SMA200_VL_ZSCR_smooth_DAY'), row=6, col=1)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Intraday ET for {ticker} on {df['TIME_EST'].dt.date.iloc[-1]}\",\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        height=900, width=1000,\n",
    "        paper_bgcolor=\"white\", plot_bgcolor=\"white\",showlegend=False  \n",
    "    )\n",
    "\n",
    "    # Gridlines\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='lightgray', rangeslider_visible=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='lightgray')\n",
    "\n",
    "    # Add vertical dashed green lines at buy conditions\n",
    "    if \"buy_condition\" in df.columns:\n",
    "        for t in df.loc[df[\"buy_condition\"], \"TIME_EST\"]:\n",
    "            fig.add_vline(x=t, line=dict(color='green', width=1, dash='dash'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = f\"{ticker} on {df['TIME_EST'].iloc[-1].strftime('%Y-%m-%d %H:%M:%S %Z')} | Last Close: {df['close'].iloc[-1]:.2f}\",\n",
    "\n",
    "        xaxis_rangeslider_visible=False,height=900, width=1000,paper_bgcolor=\"white\", plot_bgcolor=\"white\")\n",
    "\n",
    "    return fig \n",
    "\n",
    "    # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5975cbe5-c043-414a-b35c-6fe11828e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG (timezones)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ET_ZONE  = ZoneInfo(\"America/New_York\")\n",
    "TZ_PST   = ZoneInfo(\"America/Los_Angeles\")\n",
    "TZ_EST   = ZoneInfo(\"America/New_York\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN FUNCTION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def analyze_sma_runs(\n",
    "    df_day,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    time_col=\"TIME_EST\",\n",
    "    col_sma200_smooth=\"SMA200_VL_ZSCR_smooth_DAY\",\n",
    "    col_sma50=\"SMA50_VL_ZSCR_smooth_DAY\",\n",
    "    col_sma200_raw=\"SMA200_VL_ZSCR_DAY\",\n",
    "    col_close=\"close\",\n",
    "    pos_min_minutes=4,\n",
    "    neg_min_minutes=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect UP/DOWN runs on SMA200 z-score slope, summarize them, and plot:\n",
    "      - UP (diff >= 0) and DOWN (diff < 0) runs\n",
    "      - Shaded spans for runs\n",
    "      - Î” close labels on plot\n",
    "      - Tables with Open/Close/Î”/%Chg/Min and AvgDiff start/end (UP/DOWN-specific)\n",
    "    Returns: runs_up, runs_down, fig\n",
    "    \"\"\"\n",
    "    # Times\n",
    "    start_dt = datetime.combine(start_date, start_time, tzinfo=ET_ZONE)\n",
    "    end_dt   = datetime.combine(end_date,   end_time,   tzinfo=ET_ZONE)\n",
    "\n",
    "    # Window + diff\n",
    "    df = df_day.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "    mask = (df[time_col] >= start_dt) & (df[time_col] <= end_dt)\n",
    "    df_window = (\n",
    "        df.loc[mask, [time_col, col_sma200_smooth, col_close]]\n",
    "          .copy()\n",
    "          .set_index(time_col)\n",
    "          .sort_index()\n",
    "    )\n",
    "    df_window = df_window[~df_window.index.duplicated(keep=\"first\")]\n",
    "    df_window[\"diff\"] = df_window[col_sma200_smooth].diff()\n",
    "\n",
    "    diff_series = df_window[\"diff\"].dropna().sort_index()\n",
    "    tmp = diff_series.reset_index()\n",
    "    tmp.columns = [\"ts\", \"diff\"]\n",
    "\n",
    "    pos_min = pd.Timedelta(minutes=pos_min_minutes)\n",
    "    neg_min = pd.Timedelta(minutes=neg_min_minutes)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Generic run detection\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def detect_runs(tmp, start_cond):\n",
    "        \"\"\"\n",
    "        start_cond(d): True for the main sign of the run\n",
    "          - up  : d >= 0\n",
    "          - down: d <  0\n",
    "        Run starts after pos_min of start_cond\n",
    "        Run ends  after neg_min of opposite sign\n",
    "        \"\"\"\n",
    "        runs_list = []\n",
    "        current_run_start = None\n",
    "        streak_start = None        # streak for start_cond\n",
    "        opp_streak_start = None    # streak for opposite sign\n",
    "        last_main_ts = None        # last timestamp with start_cond(d) True\n",
    "\n",
    "        for ts, d in tmp.itertuples(index=False):\n",
    "            if np.isnan(d):\n",
    "                continue\n",
    "\n",
    "            if current_run_start is None:\n",
    "                # Look for pos_min of start_cond to start a run\n",
    "                if start_cond(d):\n",
    "                    if streak_start is None:\n",
    "                        streak_start = ts\n",
    "                    if ts - streak_start >= pos_min:\n",
    "                        current_run_start = streak_start\n",
    "                        last_main_ts = ts\n",
    "                        opp_streak_start = None\n",
    "                else:\n",
    "                    streak_start = None\n",
    "            else:\n",
    "                # Inside an active run\n",
    "                if start_cond(d):\n",
    "                    opp_streak_start = None\n",
    "                    last_main_ts = ts\n",
    "                else:\n",
    "                    if opp_streak_start is None:\n",
    "                        opp_streak_start = ts\n",
    "                    if ts - opp_streak_start >= neg_min:\n",
    "                        run_end = last_main_ts if last_main_ts is not None else opp_streak_start\n",
    "                        if run_end is not None and run_end > current_run_start:\n",
    "                            runs_list.append((current_run_start, run_end))\n",
    "                        current_run_start = None\n",
    "                        streak_start = None\n",
    "                        opp_streak_start = None\n",
    "                        last_main_ts = None\n",
    "\n",
    "        # If run still open at the end\n",
    "        if current_run_start is not None:\n",
    "            run_end = last_main_ts if last_main_ts is not None else tmp[\"ts\"].iloc[-1]\n",
    "            if run_end > current_run_start:\n",
    "                runs_list.append((current_run_start, run_end))\n",
    "\n",
    "        runs_df = pd.DataFrame(runs_list, columns=[\"run_start\", \"run_end\"])\n",
    "        if not runs_df.empty:\n",
    "            runs_df[\"duration\"] = runs_df[\"run_end\"] - runs_df[\"run_start\"]\n",
    "            runs_df[\"duration_min\"] = runs_df[\"duration\"].dt.total_seconds() / 60.0\n",
    "        else:\n",
    "            runs_df[\"duration\"] = pd.Timedelta(0)\n",
    "            runs_df[\"duration_min\"] = 0.0\n",
    "        return runs_df\n",
    "\n",
    "    runs_up_raw   = detect_runs(tmp, lambda d: d >= 0)\n",
    "    runs_down_raw = detect_runs(tmp, lambda d: d <  0)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Enrich runs with close, Î”, %Chg, AvgDiff start/end\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def get_close_exact_or_asof(ts):\n",
    "        if col_close in df_window.columns:\n",
    "            try:\n",
    "                return float(df_window.loc[ts, col_close])\n",
    "            except KeyError:\n",
    "                return float(df_window[col_close].asof(ts))\n",
    "        return np.nan\n",
    "\n",
    "    def enrich_runs(base_df, sign=\"up\"):\n",
    "        df_runs = base_df.copy()\n",
    "        if df_runs.empty:\n",
    "            return df_runs\n",
    "\n",
    "        df_runs[\"run_start_close\"] = df_runs[\"run_start\"].map(get_close_exact_or_asof)\n",
    "        df_runs[\"run_end_close\"]   = df_runs[\"run_end\"].map(get_close_exact_or_asof)\n",
    "\n",
    "        df_runs[\"delta_close\"] = df_runs[\"run_end_close\"] - df_runs[\"run_start_close\"]\n",
    "        df_runs[\"pct_change\"]  = np.where(\n",
    "            df_runs[\"run_start_close\"] != 0,\n",
    "            (df_runs[\"delta_close\"] / df_runs[\"run_start_close\"]) * 100.0,\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        avg_first5_list = []\n",
    "        avg_last5_list  = []\n",
    "        for row in df_runs.itertuples(index=False):\n",
    "            rs = row.run_start\n",
    "            re = row.run_end\n",
    "            seg = df_window.loc[(df_window.index >= rs) & (df_window.index <= re), \"diff\"]\n",
    "            if sign == \"up\":\n",
    "                seg_sign = seg[seg > 0]\n",
    "            else:\n",
    "                seg_sign = seg[seg < 0]\n",
    "            if not seg_sign.empty:\n",
    "                avg_first5_list.append(seg_sign.head(5).mean() * 1000)\n",
    "                avg_last5_list.append(seg_sign.tail(5).mean() * 1000)\n",
    "            else:\n",
    "                avg_first5_list.append(np.nan)\n",
    "                avg_last5_list.append(np.nan)\n",
    "\n",
    "        df_runs[\"avgdiff_start\"] = avg_first5_list\n",
    "        df_runs[\"avgdiff_end\"]   = avg_last5_list\n",
    "        return df_runs\n",
    "\n",
    "    runs_up_full   = enrich_runs(runs_up_raw,   sign=\"up\")\n",
    "    runs_down_full = enrich_runs(runs_down_raw, sign=\"down\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Build summary tables (with sign-aware AvgDiff names)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def make_summary(df_runs, sign=\"up\"):\n",
    "        if df_runs.empty:\n",
    "            return df_runs.copy()\n",
    "\n",
    "        out = df_runs.copy().reset_index(drop=True)\n",
    "        out[\"start_pst\"] = out[\"run_start\"].dt.tz_convert(TZ_PST)\n",
    "        out[\"end_pst\"]   = out[\"run_end\"].dt.tz_convert(TZ_PST)\n",
    "        out[\"start_est\"] = out[\"run_start\"].dt.tz_convert(TZ_EST)\n",
    "        out[\"end_est\"]   = out[\"run_end\"].dt.tz_convert(TZ_EST)\n",
    "\n",
    "        out[\"Start PST\"] = out[\"start_pst\"].dt.strftime(\"%H:%M\")\n",
    "        out[\"End PST\"]   = out[\"end_pst\"].dt.strftime(\"%H:%M\")\n",
    "        out[\"Start EST\"] = out[\"start_est\"].dt.strftime(\"%H:%M\")\n",
    "        out[\"End EST\"]   = out[\"end_est\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "        avg_start_col = f\"AvgDiff_{sign.upper()}_start\"\n",
    "        avg_end_col   = f\"AvgDiff_{sign.upper()}_end\"\n",
    "\n",
    "        out = out.rename(columns={\n",
    "            \"run_start_close\": \"Open\",\n",
    "            \"run_end_close\":   \"Close\",\n",
    "            \"delta_close\":     \"Î”\",\n",
    "            \"pct_change\":      \"%Chg\",\n",
    "            \"duration_min\":    \"Min\",\n",
    "            \"avgdiff_start\":   avg_start_col,\n",
    "            \"avgdiff_end\":     avg_end_col,\n",
    "        })[[\n",
    "            \"Start EST\", \"End EST\", \"Open\", \"Close\", \"Î”\", \"%Chg\", \"Min\",\n",
    "            avg_start_col, avg_end_col,\n",
    "            \"Start PST\", \"End PST\"\n",
    "        ]]\n",
    "        return out\n",
    "\n",
    "    runs_up   = make_summary(runs_up_full,   sign=\"up\")\n",
    "    runs_down = make_summary(runs_down_full, sign=\"down\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PLOT: SMA200/SMA50/CLOSE + UP (green) + DOWN (red) spans\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if time_col in df.columns:\n",
    "        ts_all = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "    else:\n",
    "        ts_all = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "    idx_all = pd.DatetimeIndex(ts_all)\n",
    "    idx_et  = idx_all.tz_localize(ET_ZONE, nonexistent=\"shift_forward\", ambiguous=\"NaT\") \\\n",
    "              if idx_all.tz is None else idx_all.tz_convert(ET_ZONE)\n",
    "\n",
    "    df_plot = df[[col_sma200_smooth, col_sma50, col_close, col_sma200_raw]].copy()\n",
    "    df_plot.index = idx_et\n",
    "    df_plot = df_plot.sort_index()\n",
    "    df_plot = df_plot.loc[(df_plot.index >= start_dt) & (df_plot.index <= end_dt)]\n",
    "    if df_plot.empty:\n",
    "        raise ValueError(\"No data in the specified ET window for plotting.\")\n",
    "\n",
    "    def to_et(ts_in):\n",
    "        ts_in = pd.Timestamp(ts_in)\n",
    "        return ts_in.replace(tzinfo=ET_ZONE) if ts_in.tzinfo is None else ts_in.tz_convert(ET_ZONE)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # SMA200 smoothed (blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot.index,\n",
    "        y=df_plot[col_sma200_smooth],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=2, color=\"blue\"),\n",
    "        name=\"SMA200_smooth\",\n",
    "        customdata=np.stack([df_plot[col_sma50], df_plot[col_close]], axis=-1),\n",
    "        hovertemplate=(\n",
    "            \"Time (ET): %{x|%H:%M}<br>\"\n",
    "            \"SMA200_smooth: %{y:.3f}<br>\"\n",
    "            \"SMA50: %{customdata[0]:.3f}<br>\"\n",
    "            \"Close: %{customdata[1]:.4f}<extra></extra>\"\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "    # SMA200 raw (orange, solid)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot.index,\n",
    "        y=df_plot[col_sma200_raw],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=1.3, color=\"orange\"),\n",
    "        name=\"SMA200_raw\",\n",
    "        hoverinfo=\"skip\"\n",
    "    ))\n",
    "\n",
    "    # SMA50 (black)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot.index,\n",
    "        y=df_plot[col_sma50],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=1.6, color=\"black\"),\n",
    "        name=\"SMA50\",\n",
    "        hoverinfo=\"skip\"\n",
    "    ))\n",
    "\n",
    "    # Close (gray, right axis, solid)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot.index,\n",
    "        y=df_plot[col_close],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=1.2, color=\"#888\"),\n",
    "        name=\"Close\",\n",
    "        yaxis=\"y2\",\n",
    "        hoverinfo=\"skip\"\n",
    "    ))\n",
    "\n",
    "    shapes = []\n",
    "    annotations = []\n",
    "\n",
    "    # UP runs shading + Î” labels\n",
    "    if not runs_up_full.empty:\n",
    "        delta_vals_up = runs_up_full[\"delta_close\"].to_numpy()\n",
    "        for i, r in enumerate(runs_up_full.itertuples(index=False)):\n",
    "            start_et = to_et(r.run_start)\n",
    "            end_et   = to_et(r.run_end)\n",
    "            if end_et < start_dt or start_et > end_dt:\n",
    "                continue\n",
    "            seg_start = max(start_et, start_dt)\n",
    "            seg_end   = min(end_et,   end_dt)\n",
    "            dv = float(delta_vals_up[i]) if i < len(delta_vals_up) else np.nan\n",
    "            if not np.isfinite(dv):\n",
    "                continue\n",
    "\n",
    "            fillcolor = \"rgba(215,245,215,0.25)\" if dv > 0 else \"rgba(200,200,200,0.25)\"\n",
    "            shapes.append(dict(\n",
    "                type=\"rect\",\n",
    "                xref=\"x\", yref=\"paper\",\n",
    "                x0=seg_start, x1=seg_end, y0=0, y1=1,\n",
    "                fillcolor=fillcolor, line=dict(width=0)\n",
    "            ))\n",
    "\n",
    "            x_mid = seg_start + (seg_end - seg_start) / 2\n",
    "            annotations.append(dict(\n",
    "                x=x_mid, y=0.92, xref=\"x\", yref=\"paper\",\n",
    "                text=(f\"+{dv:.2f}\" if dv > 0 else f\"{dv:.2f}\"),\n",
    "                showarrow=False,\n",
    "                font=dict(size=11, color=(\"#1a7f37\" if dv > 0 else \"dimgray\")),\n",
    "                bgcolor=\"white\", borderpad=2, opacity=0.9\n",
    "            ))\n",
    "\n",
    "    # DOWN runs shading (light red) + Î” labels\n",
    "    if not runs_down_full.empty:\n",
    "        delta_vals_down = runs_down_full[\"delta_close\"].to_numpy()\n",
    "        for i, r in enumerate(runs_down_full.itertuples(index=False)):\n",
    "            start_et = to_et(r.run_start)\n",
    "            end_et   = to_et(r.run_end)\n",
    "            if end_et < start_dt or start_et > end_dt:\n",
    "                continue\n",
    "            seg_start = max(start_et, start_dt)\n",
    "            seg_end   = min(end_et,   end_dt)\n",
    "\n",
    "            shapes.append(dict(\n",
    "                type=\"rect\",\n",
    "                xref=\"x\", yref=\"paper\",\n",
    "                x0=seg_start, x1=seg_end, y0=0, y1=1,\n",
    "                fillcolor=\"rgba(255,180,180,0.28)\",\n",
    "                line=dict(width=0)\n",
    "            ))\n",
    "\n",
    "            dv = float(delta_vals_down[i]) if i < len(delta_vals_down) else np.nan\n",
    "            if not np.isfinite(dv):\n",
    "                continue\n",
    "            x_mid = seg_start + (seg_end - seg_start) / 2\n",
    "            annotations.append(dict(\n",
    "                x=x_mid, y=0.92, xref=\"x\", yref=\"paper\",\n",
    "                text=f\"{dv:.2f}\",      # typically negative\n",
    "                showarrow=False,\n",
    "                font=dict(size=11, color=\"#b91c1c\"),\n",
    "                bgcolor=\"white\", borderpad=2, opacity=0.9\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"SMA200 (blue) + SMA200_raw (orange) vs SMA50 (black) with Close Overlay â€” UP (green) & DOWN (red) runs\",\n",
    "        xaxis_title=\"Time (ET)\",\n",
    "        yaxis=dict(title=\"Z-score\"),\n",
    "        yaxis2=dict(\n",
    "            title=\"Close\",\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            showgrid=False\n",
    "        ),\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\",\n",
    "        showlegend=True,\n",
    "        shapes=shapes,\n",
    "        annotations=annotations,\n",
    "        margin=dict(l=60, r=50, t=60, b=40),\n",
    "        hoverlabel=dict(bgcolor=\"white\", bordercolor=\"rgba(0,0,0,0)\", font=dict(color=\"black\"))\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=0.5)\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=0.5)\n",
    "    fig.add_hline(y=0, line_width=1, line_dash=\"dash\", opacity=0.7)\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        rangeslider=dict(visible=True, thickness=0.08),\n",
    "        rangeselector=dict(\n",
    "            buttons=[\n",
    "                dict(step=\"minute\", stepmode=\"backward\", count=15, label=\"15m\"),\n",
    "                dict(step=\"minute\", stepmode=\"backward\", count=30, label=\"30m\"),\n",
    "                dict(step=\"hour\",   stepmode=\"backward\", count=1,  label=\"1h\"),\n",
    "                dict(step=\"all\",    label=\"All\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return runs_up, runs_down, fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77696a91-a977-4d49-ba5e-cbc35bfa4be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5758f-4974-4711-a231-767c6f84235f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e5accf7-4b06-4be2-89bb-9bc999386a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error fetching PLTR: HTTPSConnectionPool(host='api.polygon.io', port=443): Max retries exceeded with url: /v2/aggs/ticker/PLTR/range/1/minute/2025-11-18/2025-11-18?apiKey=vBRy5un9PuHfxFj1IrHpfg8a2RS57jE9&adjusted=true&sort=asc&limit=50000 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x128e5bd00>, 'Connection to api.polygon.io timed out. (connect timeout=None)'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# 1) Run and DISPLAY results\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# 2) Keep results visible with a countdown (no clearing yet)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ” Auto-refresh at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mnow())\n",
      "Cell \u001b[0;32mIn[14], line 53\u001b[0m, in \u001b[0;36mrun_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     df_day \u001b[38;5;241m=\u001b[39m all_data_minute\u001b[38;5;241m.\u001b[39mget(tic)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ONE-LINE USAGE IN THE SAME CELL\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m runs_up, runs_down, fig \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sma_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_date_TRADE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_date_TRADE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_time_TRADE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_time_TRADE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m display(runs_up)\n\u001b[1;32m     56\u001b[0m display(runs_down)\n",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m, in \u001b[0;36manalyze_sma_runs\u001b[0;34m(df_day, start_date, end_date, start_time, end_time, time_col, col_sma200_smooth, col_sma50, col_sma200_raw, col_close, pos_min_minutes, neg_min_minutes)\u001b[0m\n\u001b[1;32m     41\u001b[0m end_dt   \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mcombine(end_date,   end_time,   tzinfo\u001b[38;5;241m=\u001b[39mET_ZONE)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Window + diff\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_day\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m     45\u001b[0m df[time_col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[time_col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m mask \u001b[38;5;241m=\u001b[39m (df[time_col] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_dt) \u001b[38;5;241m&\u001b[39m (df[time_col] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_dt)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Inputs =====\n",
    "# Add example 100 tickers\n",
    "\n",
    "TICKERS=['PLTR']\n",
    "\n",
    "# Time window for filtering intraday bars (Eastern Time)\n",
    "\n",
    "# ===== Inputs =====\n",
    "start_date_DATA = date(2025, 11, 18)\n",
    "end_date_DATA = date(2025, 11, 18)\n",
    "\n",
    "start_time_DATA = dt_time(0, 0)   # ex.,4:00 AM ET\n",
    "end_time_DATA = dt_time(20, 0)    #ex.,4:00 PM ET\n",
    "#--------------------------------------------------\n",
    "start_date_TRADE = date(2025, 11, 18)\n",
    "end_date_TRADE = date(2025, 11, 18)\n",
    "\n",
    "start_time_TRADE = dt_time(0, 0)   # ex.,4:00 AM ET\n",
    "end_time_TRADE = dt_time(23, 59)    #ex.,4:00 PM ET\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd  # only if you print timestamps\n",
    "\n",
    "REFRESH_EVERY = 55  # seconds\n",
    "\n",
    "def run_analysis():\n",
    "    # ðŸ”½ Put your entire analysis/plot/table code here\n",
    "    #===========================================================================================================================================\n",
    "\n",
    "        \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # GET DATA\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    multiplier = 1               #   e.g., 1-minute bars,  5-minute bars, etc.\n",
    "    timespan = \"minute\"          #  \"second\", \"minute\", \"hour\", \"day\", etc.\n",
    "    limit = 50000\n",
    "        \n",
    "    all_data_minute = fetch_multiple_tickers_data(ticker=TICKERS,api_key=API_KEY,start_date=start_date_DATA,end_date=end_date_DATA,start_time=start_time_DATA,end_time=end_time_DATA,multiplier=multiplier,timespan=timespan,limit=limit)\n",
    "        \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Do Not  plot\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for tic in TICKERS:\n",
    "            # df_day = all_data_minute_processed.get(tic)\n",
    "        df_day = all_data_minute.get(tic)\n",
    "        \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # ONE-LINE USAGE IN THE SAME CELL\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    runs_up, runs_down, fig = analyze_sma_runs(df_day,start_date_TRADE,end_date_TRADE,start_time_TRADE,end_time_TRADE)\n",
    "    \n",
    "    display(runs_up)\n",
    "    display(runs_down)\n",
    "    fig.show()\n",
    "    \n",
    "    #===========================================================================================================================================\n",
    "    # (everything up to and including plt.show())\n",
    "    pass\n",
    "\n",
    "while True:\n",
    "    # 1) Run and DISPLAY results\n",
    "    run_analysis()\n",
    "\n",
    "    # 2) Keep results visible with a countdown (no clearing yet)\n",
    "    print(\"ðŸ” Auto-refresh at:\", pd.Timestamp.now())\n",
    "    for i in range(REFRESH_EVERY, 0, -1):\n",
    "        sys.stdout.write(f\"\\rNext refresh in {i:2d}s \")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(1)\n",
    "\n",
    "    # 3) NOW clear, so next loop starts fresh\n",
    "    clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b378c-4048-432c-8bfe-4edcc21efc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add AVG last 5 min\n",
    "# look at daily movers\n",
    "\n",
    "# time: 10:16\n",
    "# levergaed : 11:33\n",
    "# stock : 105:25\n",
    "# 11.05 to 11.57\n",
    "\n",
    "\n",
    "# both decreasing (positive toward negative), sma50 is lower than sma 200 : sharp deacrease (9:50 t0 12) : 107. - 103.83 \n",
    "#* hint: TSI is negative, decreasing , blue line over red line, RSI decreasing, MACD negative, VWAP below SMA200\n",
    "\n",
    "# both increasing (negative toward positive) , sma50 is above sam200 : strong increase (12:05 to 12:46): 105.44 - 106.11 \n",
    "#**** Note: when sma50 reach max z score therwill be pull back\n",
    "# * TSI at negative arera turn into positive, redline cross bluse line, MACD start increase, RSI increas VWAP get close and cross over SMA200\n",
    "\n",
    "# fluactuating near zero line : discard \n",
    "# MACD Signal weak, RSI constant, TSI near zero\n",
    "\n",
    "# sma 200 increasing in postive side and sma5o is increasing from negative side: price mildly increases (14:45 to 15:20 )104.2 to 103.3\n",
    "# TSI increaing, red line cross blue line, RSI incresing MACD increasing\n",
    "\n",
    "\n",
    "# sma200 increasing sma 50 fluctuate: \n",
    "\n",
    "# sma200 increasing in negative side and sma50 is decreasing in positive side: fluctuation\n",
    "\n",
    "#sma200 increasing in opositive side and sma50 is fluctuating , price deacrse or flucatuate, bad tiem (12:45 to 14:45)\n",
    "\n",
    "# If a stock rised during after hours, it is possible it decearse at 6:30, since poepl have wakeed up are profit taking\n",
    "\n",
    "# dont enter chobbi trends near the 0 line\n",
    "\n",
    "# dont enter in the middle of the trend\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d98697-f721-41d5-841c-a1496dc6dd81",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
